{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**InPoDa:Collecte, Traitement, et Analyse de Donn√©es de R√©seaux Sociaux**</u>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momtaz Ilies TD03\n",
    "Larouco Th√©o TD03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet, r√©alis√© en L2 INFO √† l'UVSQ, porte sur la collecte, le traitement et l'analyse de donn√©es √† partir d'un jeu de tweets au format JSON. Il vise √† d√©velopper une plateforme virtuelle nomm√©e InPoDA, permettant √† un analyste d'explorer de mani√®re autonome diverses informations sur le jeu de tweets qu'il souhaite analyser, gr√¢ce √† un ensemble d'op√©rations propos√©es par la plateforme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biblioth√®ques utilis√©es dans le Projet Inpoda\n",
    "\n",
    "1. **Importation des biblioth√®ques** :\n",
    "    - `json` : pour travailler avec des donn√©es au format JSON.\n",
    "    - `re` : pour effectuer des op√©rations de recherche de motifs (regex).\n",
    "    - `pandas` : pour manipuler et analyser des donn√©es tabulaires avec des DataFrames.\n",
    "    - `TextBlob` de la biblioth√®que `textblob` : pour effectuer une analyse de sentiment sur le texte des tweets.\n",
    "    - `matplotlib.pyplot` : pour cr√©er des visualisations avec Matplotlib.\n",
    "    - `random` : pour g√©n√©rer des nombres al√©atoires.\n",
    "    - `plotly.express` : pour cr√©er des visualisations interactives avec Plotly Express.\n",
    "    - `seaborn` : pour am√©liorer le style des graphiques avec Seaborn.\n",
    "    - `corpora` et `models` de la biblioth√®que `gensim` : pour effectuer une analyse de texte avec le mod√®le Bag of Words.\n",
    "    - `word_tokenize` et `stopwords` de la biblioth√®que `nltk` : pour le traitement du langage naturel.\n",
    "    - `preprocess_string` de la biblioth√®que `gensim.parsing.preprocessing` : pour pr√©traiter les cha√Ænes de texte.\n",
    "    - `detect` de la biblioth√®que `langdetect` : pour d√©tecter la langue du texte.\n",
    "\n",
    "2. **Fonction Sentiment Analysis** :\n",
    "    - Une fonction `sentiment(tweet_id)` qui prend un identifiant de tweet, extrait le texte associ√© √† l'aide de Pandas, puis utilise TextBlob pour calculer la polarit√© du sentiment.\n",
    "\n",
    "3. **Utilisation de Plotly Express** :\n",
    "    - Utilisation de Plotly Express pour cr√©er un graphique interactif √† barres des hashtags les plus courants.\n",
    "\n",
    "4. **Utilisation de Seaborn et Matplotlib** :\n",
    "    - Utilisation de Seaborn pour am√©liorer le style des graphiques.\n",
    "    - Utilisation de Matplotlib pour cr√©er un graphique √† barres des arobases les plus mentionn√©es.\n",
    "\n",
    "5. **Analyse de texte avec Gensim et NLTK** :\n",
    "    - Utilisation de Gensim et NLTK pour effectuer une analyse de texte, y compris la tokenisation et le retrait des mots vides.\n",
    "\n",
    "N'oubliez pas d'installer les biblioth√®ques n√©cessaires en utilisant `pip install [nom de la biblioth√®que]` si elles ne sont pas d√©j√† install√©es."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "from gensim import corpora, models\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from langdetect import detect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le DataFrame \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"zone_atterissage.json\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouver les tweets affili√©s √† une mention utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_user_mention(mention):\n",
    "    for tweet in df[\"TweetText\"]:\n",
    "        if mention in tweet:\n",
    "            print(mention)\n",
    "            print(tweet)\n",
    "find_user_mention(\"@jason_lazer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouver les tweets affili√©s √† un hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_user_hashtags(hashtag):\n",
    "    for tweet in df[\"TweetText\"]:\n",
    "        if hashtag in tweet:\n",
    "            print(hashtag)\n",
    "            print(tweet)\n",
    "find_user_hashtags(\"#ml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trouver les tweets affili√©s √† un utilisateur specifique "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_user(user):\n",
    "    # Nom de l'auteur √† rechercher\n",
    "    nom_auteur_recherche = user\n",
    "\n",
    "    # Filtrer les tweets de l'auteur sp√©cifi√©\n",
    "    tweets_auteur = df[df[\"Author\"] == nom_auteur_recherche]\n",
    "\n",
    "    # V√©rifier si des tweets ont √©t√© trouv√©s pour l'auteur sp√©cifi√©\n",
    "    if not tweets_auteur.empty:\n",
    "        # Acc√©der au texte de tous les tweets de l'auteur\n",
    "        textes_tweets_auteur = tweets_auteur[\"TweetText\"].tolist()\n",
    "\n",
    "        # Afficher les textes des tweets\n",
    "        for texte_tweet in textes_tweets_auteur:\n",
    "            print(\"Texte du tweet:\", texte_tweet)\n",
    "            print(\"\\n\")\n",
    "    else:\n",
    "        print(\"Aucun tweet trouv√© pour l'auteur sp√©cifi√©.\")\n",
    "\n",
    "find_user(\"VagueDePlume\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de la liste de hashtags de la publication avec l'autheur du tweet\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def extraction_hashtags(id):\n",
    "    tweet_recherche = df.loc[df['Author'] == id]\n",
    "    texte_du_tweet = tweet_recherche['TweetText'].values[0]\n",
    "    pattern = r'#\\w+'\n",
    "    print(texte_du_tweet)\n",
    "    print(re.findall(pattern, texte_du_tweet))\n",
    "extraction_hashtags(\"OrageTwitter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de sentiment de la publication (le sentiment peut √™tre positif ou bien n√©gatif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(id):\n",
    "    s = df.loc[df['id'] == id]\n",
    "    texte= s['TweetText']\n",
    "    texte=str(texte)\n",
    "    blob =TextBlob(texte)\n",
    "    sentiment = blob.sentiment\n",
    "    r=sentiment.polarity\n",
    "    if r<=0:\n",
    "        return 'üòû'\n",
    "    else:\n",
    "        return 'üòÄ'\n",
    "\n",
    "print(sentiment(1415291877897605120))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Extraction de la liste des utilisateurs mentionn√©es de la publication avec l'autheur du tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraction_user(id):\n",
    "    tweet_recherche = df.loc[df['Author'] == id]\n",
    "    texte_du_tweet = tweet_recherche['TweetText'].values[0]\n",
    "    pattern = r'@\\w+'\n",
    "    print(texte_du_tweet)\n",
    "    liste = re.findall(pattern, texte_du_tweet)\n",
    "    return liste\n",
    "extraction_user(\"RafaleTweeter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le nombre de publications par utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_pub_par_user(auteur):\n",
    "    s=0\n",
    "    for i in df[\"Author\"]:\n",
    "        if auteur==i:\n",
    "            s=s+1\n",
    "    return s\n",
    "print(nb_pub_par_user(str(input(\"user: \"))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_hashtag(k):\n",
    "    hashtags_freq = {}  # Dictionnaire pour stocker la fr√©quence des hashtags\n",
    "\n",
    "    for tweet_text in df[\"TweetText\"]:\n",
    "        hashtags = re.findall(r'#\\w+', tweet_text)  # Trouver tous les hashtags dans le texte\n",
    "        for hashtag in hashtags:\n",
    "            # Convertir en minuscules pour compter de mani√®re insensible √† la casse\n",
    "            hashtag = hashtag.lower()\n",
    "            if hashtag in hashtags_freq:\n",
    "                hashtags_freq[hashtag] += 1\n",
    "            else:\n",
    "                hashtags_freq[hashtag] = 1\n",
    "\n",
    "    # Trier les hashtags par fr√©quence d√©croissante\n",
    "    sorted_hashtags = sorted(hashtags_freq.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # S√©lectionner les k hashtags les plus courants\n",
    "    top_k_hashtags = dict(sorted_hashtags[:k])\n",
    "\n",
    "    # Cr√©er un graphique √† barres avec Matplotlib\n",
    "    plt.bar(top_k_hashtags.keys(), top_k_hashtags.values())\n",
    "    plt.xlabel('Hashtags')\n",
    "    plt.ylabel('Fr√©quence')\n",
    "    plt.title(f'Top {k} Hashtags')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()\n",
    "\n",
    "# Exemple d'utilisation pour afficher les 5 hashtags les plus courants\n",
    "topk_hashtag(int(input(\"Top K hashtags : \")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topKmentionne(k):\n",
    "    dic={}\n",
    "    for tweet in df[\"TweetText\"]:\n",
    "        arobases = re.findall(r'@\\w+', tweet)\n",
    "        for arobase in arobases:\n",
    "              # Convertir en minuscules pour compter de mani√®re insensible √† la casse\n",
    "            if arobase in dic:\n",
    "                dic[arobase] += 1\n",
    "            else:\n",
    "                dic[arobase] = 1\n",
    "    sorted_arobases = sorted(dic.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k_arobases = dict(sorted_arobases[:k])\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.bar(top_k_arobases.keys(), top_k_arobases.values(), color=sns.color_palette(\"viridis\"))\n",
    "    plt.xlabel(\"Arobase\")\n",
    "    plt.ylabel(\"Frequence\")\n",
    "    plt.title(f\"Top {k} arobase\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()\n",
    "topKmentionne(int(input(\"Top K arobase: \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top K utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topk_utilisateur(k):\n",
    "    dico={}\n",
    "    p=[]\n",
    "    for auteur in df[\"Author\"]:\n",
    "        if auteur in dico:\n",
    "            dico[auteur]+=1\n",
    "        else:\n",
    "            dico[auteur]=1\n",
    "    sorted_utlisateur = sorted(dico.items(), key=lambda x: x[1], reverse=True)\n",
    "    top_k_user = dict(sorted_utlisateur[:k])\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "\n",
    "    plt.bar(top_k_user.keys(), top_k_user.values(), color='skyblue')\n",
    "    plt.xlabel(\"Utilisateur\")\n",
    "    plt.ylabel(\"Fr√©quence\")\n",
    "    plt.title(f\"Top {k} Utilisateur\")\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "print(topk_utilisateur(int(input(\"Top K utilisateur: \"))))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
